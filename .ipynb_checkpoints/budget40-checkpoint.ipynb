{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aos/home/jlavoie/.conda/envs/a/lib/python3.7/site-packages/ipykernel_launcher.py:7: MatplotlibDeprecationWarning: \n",
      "The mpl_toolkits.axes_grid module was deprecated in Matplotlib 2.1 and will be removed two minor releases later. Use mpl_toolkits.axes_grid1 and mpl_toolkits.axisartist, which provide the same functionality instead.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "import pickle\n",
    "import cftime\n",
    "from mpl_toolkits.axes_grid.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "#from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
    "\n",
    "\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 24\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set constants\n",
    "path='/storage/jlavoie/Research/Data/Budget/'\n",
    "fTEMP=Dataset(path+'b.e11.BRCP85C5CNBDRD.f09_g16.002.pop.h.TEMP.200601-208012.nc')\n",
    "fTEMP1=Dataset(path+'b.e11.B20TRC5CNBDRD.f09_g16.002.pop.h.TEMP.192001-200512.nc')\n",
    "faice=Dataset(path+'b.e11.BRCP85C5CNBDRD.f09_g16.002.cice.h.aice_nh.200601-208012.nc')\n",
    "\n",
    "\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "nbDaysInMonth=[31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "\n",
    "\n",
    "rho_sw=fTEMP['rho_sw'][:]*1000#kg m-3\n",
    "cp_sw=fTEMP['cp_sw'][:]*0.0001#J kg-1 K-1\n",
    "T2E=rho_sw*cp_sw#J degC-1 m-3 # convert temperature to energy density\n",
    "\n",
    "latent_heat_vapor=fTEMP['latent_heat_vapor'][:]\n",
    "latent_heat_fusion=fTEMP1['latent_heat_fusion'][:]*1e-7*1000# erg/g -> J/kg\n",
    "rho_ice=917#kg/m3\n",
    "\n",
    "dz=fTEMP['dz'][:]*0.01# m\n",
    "dzw=fTEMP['dzw'][:]*0.01# m\n",
    "Tf=-1.8\n",
    "tlong=fTEMP['TLONG'][:]\n",
    "tlat=fTEMP['TLAT'][:]\n",
    "tlon=faice['TLON'][:]\n",
    "tla=faice['TLAT'][:]\n",
    "z_t=fTEMP['z_t'][:]*0.01#m\n",
    "z_w=fTEMP['z_w'][:]*0.01#m\n",
    "z_w_top=fTEMP['z_w_top'][:]*0.01#m\n",
    "z_w_bot=fTEMP['z_w_bot'][:]*0.01#m\n",
    "\n",
    "\n",
    "timeDay1=fTEMP1['time']\n",
    "#fix month error in cesm\n",
    "Jan1920=cftime.DatetimeNoLeap(1920, 1, 1, 0, 0, 0, 0, 0, 0)\n",
    "time1 = netCDF4.num2date(timeDay1[:],timeDay1.units,calendar=timeDay1.calendar)\n",
    "time1=[Jan1920]+list(time1[:-1])\n",
    "time_boundDay1=fTEMP1['time_bound']\n",
    "time_bound1 = netCDF4.num2date(time_boundDay1[:],timeDay1.units,calendar=timeDay1.calendar)\n",
    "ind1970, ind1980= 600,720\n",
    "\n",
    "timeDay=fTEMP['time']\n",
    "time = netCDF4.num2date(timeDay[:],timeDay.units,calendar=timeDay.calendar)\n",
    "#fix month error in cesm\n",
    "Jan2006=cftime.DatetimeNoLeap(2006, 1, 1, 0, 0, 0, 0, 0, 0)\n",
    "time=[Jan2006]+list(time[:-1])\n",
    "time_boundDay=fTEMP['time_bound']\n",
    "time_bound = netCDF4.num2date(time_boundDay[:],timeDay.units,calendar=timeDay.calendar)\n",
    "ind2010,ind2020=12*4,12*14\n",
    "\n",
    "\n",
    "\n",
    "# create mask of the Cananda Basin\n",
    "# ocean (384,320)\n",
    "maskCBocn=np.zeros((384,320))\n",
    "for i in range(384):\n",
    "    for j in range(320):\n",
    "        if  205<=tlong[i,j]<=230 and 72<=tlat[i,j]<=80:\n",
    "            maskCBocn[i,j]=1\n",
    "#ice (384,320)         \n",
    "maskCBice=np.zeros((104,320))\n",
    "for i in range(104):\n",
    "    for j in range(320):\n",
    "        if  205<=tlon[i,j]<=230 and 72<=tla[i,j]<=80:\n",
    "            maskCBice[i,j]=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# heat budget (for figure 2-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCESM='/storage/jlavoie/Research/Data/CESM-LE/'\n",
    "\n",
    "#list of string with numberof EM\n",
    "EM=['00'+str(i) if i<10 else  '0'+str(i) if i<100 else ' '   for i in range(1,36)] +[str(i) for i in range(101,106)]\n",
    "#cesm variable needed to calculate the flux of element of the budget\n",
    "varByFlux={'deltaFsw':['QSW_3D'],\n",
    "    'Fsens':['SENH_F'],'Fsw':['SHF_QSW','fswthru_ai'],'Fevap':['EVAP_F'],'Flw':['LWDN_F','LWUP_F'],'Ffrazil':['QFLUX'],\n",
    "           'Fio':['MELTH_F'],'Fhor':['ADVT','HDIFT'],'Fsw,io':['fswthru_ai'],\n",
    "           'Fct':['fcondtop_ai'],'Fcb':['congel','meltb','meltl','MELTH_F'],\n",
    "           'Fsw,pen':['flat_ai','fsens_ai','flwup_ai','flwdn','aice','fswabs_ai','fsurf_ai'],\n",
    "           'dEdt':['TEMP'],'SIC':['aice'],\n",
    "           'Fsw,ai':['fswabs_ai'],'Flat,ai':['flat_ai'],'Fsens,ai':['fsens_ai'],'Flw,ai':['flwdn','aice','flwup_ai'],\n",
    "           'dhdt_b,l':['meltl','meltb','congel'],'dhdt_f':['frazil'],'dhdt_s':['meltt']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#dictionnary where we store (40em,12 months) for each flux, before calculating mean and std\\n\\nbudget_40=[{'deltaFsw':[],'Fsens':[],'Fsw':[],'Fevap':[],'Flw':[],'Ffrazil':[],'Fio':[],'Fhor':[],'Fsw,io':[],'Fct':[],\\n                    'Fcb':[],'Fsw,pen':[],'dEdt':[],'SIC':[],'Fsw,ai':[],'Flat,ai':[],'Fsens,ai':[],'Flw,ai':[],\\n                   'dhdt_b,l':[],'dhdt_f':[],'dhdt_s':[]},{'deltaFsw':[],'Fsens':[],'Fsw':[],'Fevap':[],'Flw':[],'Ffrazil':[],'Fio':[],'Fhor':[],'Fsw,io':[],'Fct':[],\\n                    'Fcb':[],'Fsw,pen':[],'dEdt':[],'SIC':[],'Fsw,ai':[],'Flat,ai':[],'Fsens,ai':[],'Flw,ai':[],\\n                   'dhdt_b,l':[],'dhdt_f':[],'dhdt_s':[]}]\\n\\ntimeBD=time_boundDay1[indA-1:indB+1]# get time for right window\\nDeltaTime=[(x[1]-x[0])*86400 for x in timeBD]# nb of days in the months and put in sec\\nbudgetMean=[]\\nbudgetStd=[]\\nbudgetMax=[]\\nbudgetMin=[]\\n\\nfor p in range(1,2):# iterate between 2 periods\\n    if p==0:\\n        indA,indB=ind1970,ind1980\\n        run='B20TRC5CNBDRD'\\n    else:\\n        indA,indB=ind2010,ind2020\\n        run='BRCP85C5CNBDRD'\\n    for em in EM: # iterate on each EM\\n        print(em)\\n        for f in budget_40[p]: # iterate through the fluxes we want to calculate\\n            if f=='deltaFsw' and em=='001':\\n                break\\n            varNeeded=[]\\n            for var in varByFlux[f]: # download the variables you need for the calculation of the flux f\\n                #specifics of filename\\n                model='pop'\\n                varHemi=var\\n                if var[0].islower():\\n                    model='cice'\\n                    varHemi=var+'_nh'#add hemisphere for name of file\\n                push1920=0\\n                if p==0:\\n                    if em=='001':\\n                        date='185001-200512'\\n                        push1920=840#push index to start at 1920 not 1850\\n                            \\n                    else:\\n                        date='192001-200512'          \\n                else:\\n                    if int(em)>=34 and p==1:\\n                        date='200601-210012'\\n                    else:\\n                        date='200601-208012'\\n                        \\n                fileEM=Dataset(pathCESM+var+'/b.e11.'+run+'.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\\n                if em=='001':\\n                    varNeeded.append(fileEM[var][840:])\\n                elif f=='deltaFsw':\\n                    cutVar=fileEM[var][indA+push1920:indB+push1920,:,-104:]# cut like this because it is faster\\n                    varNeeded.append(cutVar[:,:,maskCBice==1])\\n                else:\\n                    varNeeded.append(fileEM[var][:])\\n\\n\\n\\n\\n            #mean 1970-1979 and CB\\n            if f=='Fevap':# need to multiply by latent heat\\n                #avg over years and position\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]*latent_heat_vapor\\n                                                    for m in range(12)],axis=(1,2))\\n            elif f=='Fhor':#transform from cm C s-1 to W m-2\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]*T2E/100\\n                                                +varNeeded[1][indA+m:indB+m:12][:,maskCBocn==1]*T2E/100\\n                                                for m in range(12)],axis=(1,2))\\n            elif f=='Flw':\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]\\n                                                +varNeeded[1][indA+m:indB+m:12][:,maskCBocn==1]\\n                                                for m in range(12)],axis=(1,2))\\n            elif f=='Fsw':\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]\\n                                                -varNeeded[1][indA+m:indB+m:12][:,maskCBice==1]\\n                                                for m in range(12)],axis=(1,2))\\n            elif f=='Flw,ai':\\n                dataVar_CB=np.nanmean([(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\\n                                                *varNeeded[1][indA+m:indB+m:12][:,maskCBice==1]/100)\\n                                                +varNeeded[2][indA+m:indB+m:12][:,maskCBice==1]\\n                                                for m in range(12)],axis=(1,2))\\n            elif f=='dhdt_b,l':# if lower case=> on ice grid\\n                dataVar_CB=np.nanmean([-varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\\n                                                -varNeeded[1][indA+m:indB+m:12][:,maskCBice==1]\\n                                                +varNeeded[2][indA+m:indB+m:12][:,maskCBice==1]\\n                                                for m in range(12)],axis=(1,2))*nbDaysInMonth\\n            elif f[:4]=='dhdt':\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\\n                                                for m in range(12)],axis=(1,2))*nbDaysInMonth\\n            elif f=='dEdt':\\n                E_sumDepth=np.nansum(np.nanmean(varNeeded[0][indA-1:indB+1][:,:,maskCBocn==1],axis=(2))*dz*T2E,axis=1)\\n                wAvgTemp=[((E_sumDepth[i]*DeltaTime[i]) + (E_sumDepth[i+1]*DeltaTime[i+1]))/(DeltaTime[i]+DeltaTime[i+1]) for i in range(121)]\\n                dEdt_sumDepth=[(wAvgTemp[i]-wAvgTemp[i-1])/DeltaTime[i] for i in range(1,121)]\\n                dataVar_CB=np.nanmean([dEdt_sumDepth[m::12] for m in range(12)],axis=1)\\n\\n            elif f=='Fcb':\\n                dhdtb=(varNeeded[0][indA:indB][:,maskCBice==1]-varNeeded[1][indA:indB][:,maskCBice==1])/100/86400 # m/s\\n                meltl=varNeeded[2][indA:indB][:,maskCBice==1]/100/86400 # m/s\\n                Fmeltb=varNeeded[3][indA:indB][:,maskCBocn==1]-(-latent_heat_fusion*rho_ice*meltl)\\n                condbot_est=(-dhdtb*latent_heat_fusion*rho_ice)+Fmeltb\\n                dataVar_CB=np.nanmean([condbot_est[m::12]for m in range(12)],axis=(1,2))\\n\\n            elif f=='Fsw,pen':\\n                pen=(varNeeded[0]+varNeeded[1]+varNeeded[2]+(varNeeded[3]*varNeeded[4]/100)+varNeeded[5]-varNeeded[6])\\n                dataVar_CB=np.nanmean([pen[indA+m:indB+m:12][:,maskCBice==1]for m in range(12)],axis=(1,2))\\n\\n            elif f=='deltaFsw':\\n                #(Fsw(z=0) - Fsw(z=10) )\\n                dataVar_CB=np.nanmean([(varNeeded[0][m::12,0]-varNeeded[0][m::12,1]) for m in range(12)],axis=(1,2))\\n    \\n            elif var[0].islower():# if lower case=> on ice grid\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\\n                                                for m in range(12)],axis=(1,2))\\n                \\n            else:\\n                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]\\n                                                for m in range(12)],axis=(1,2))\\n            budget_40[p][f].append(dataVar_CB)\\n\\n    for f in budget_40[p]:\\n        budget_40[p][f]=np.array(budget_40[p][f])\\n    budget_40[p]['residual']=budget_40[p]['dEdt']-(budget_40[p]['Fsw']+budget_40[p]['Flw']+\\n                                                              budget_40[p]['Fsens']+budget_40[p]['Fevap']+\\n                                                              budget_40[p]['Fio']+budget_40[p]['Fhor']+\\n                                                              budget_40[p]['Fsw,io']+budget_40[p]['Ffrazil'])\\n    \\n    budget_40[p]['R']=(budget_40[p]['Fevap']+budget_40[p]['Fsens']+budget_40[p]['Ffrazil']+budget_40[p]['Flw']+\\n                        budget_40[p]['deltaFsw'])\\n    \\n\\n    # mean, std, min,max over the 40 ems\\n    meanB={}\\n    stdB={}\\n    maxB={}\\n    minB={}\\n    for f in budget_40[p]:\\n        meanB[f]=np.nanmean(budget_40[p][f],axis=0)\\n        stdB[f]=np.nanstd(budget_40[p][f],axis=0)\\n        maxB[f]=np.nanmax(budget_40[p][f],axis=0)\\n        minB[f]=np.nanmin(budget_40[p][f],axis=0)\\n    budgetMean.append(meanB)\\n    budgetStd.append(stdB)\\n    budgetMax.append(maxB)\\n    budgetMin.append(minB)\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for each EM calculate all variables than take mean of all\n",
    "\"\"\"\n",
    "#dictionnary where we store (40em,12 months) for each flux, before calculating mean and std\n",
    "\n",
    "budget_40=[{'deltaFsw':[],'Fsens':[],'Fsw':[],'Fevap':[],'Flw':[],'Ffrazil':[],'Fio':[],'Fhor':[],'Fsw,io':[],'Fct':[],\n",
    "                    'Fcb':[],'Fsw,pen':[],'dEdt':[],'SIC':[],'Fsw,ai':[],'Flat,ai':[],'Fsens,ai':[],'Flw,ai':[],\n",
    "                   'dhdt_b,l':[],'dhdt_f':[],'dhdt_s':[]},{'deltaFsw':[],'Fsens':[],'Fsw':[],'Fevap':[],'Flw':[],'Ffrazil':[],'Fio':[],'Fhor':[],'Fsw,io':[],'Fct':[],\n",
    "                    'Fcb':[],'Fsw,pen':[],'dEdt':[],'SIC':[],'Fsw,ai':[],'Flat,ai':[],'Fsens,ai':[],'Flw,ai':[],\n",
    "                   'dhdt_b,l':[],'dhdt_f':[],'dhdt_s':[]}]\n",
    "\n",
    "timeBD=time_boundDay1[indA-1:indB+1]# get time for right window\n",
    "DeltaTime=[(x[1]-x[0])*86400 for x in timeBD]# nb of days in the months and put in sec\n",
    "budgetMean=[]\n",
    "budgetStd=[]\n",
    "budgetMax=[]\n",
    "budgetMin=[]\n",
    "\n",
    "for p in range(1,2):# iterate between 2 periods\n",
    "    if p==0:\n",
    "        indA,indB=ind1970,ind1980\n",
    "        run='B20TRC5CNBDRD'\n",
    "    else:\n",
    "        indA,indB=ind2010,ind2020\n",
    "        run='BRCP85C5CNBDRD'\n",
    "    for em in EM: # iterate on each EM\n",
    "        print(em)\n",
    "        for f in budget_40[p]: # iterate through the fluxes we want to calculate\n",
    "            if f=='deltaFsw' and em=='001':\n",
    "                break\n",
    "            varNeeded=[]\n",
    "            for var in varByFlux[f]: # download the variables you need for the calculation of the flux f\n",
    "                #specifics of filename\n",
    "                model='pop'\n",
    "                varHemi=var\n",
    "                if var[0].islower():\n",
    "                    model='cice'\n",
    "                    varHemi=var+'_nh'#add hemisphere for name of file\n",
    "                push1920=0\n",
    "                if p==0:\n",
    "                    if em=='001':\n",
    "                        date='185001-200512'\n",
    "                        push1920=840#push index to start at 1920 not 1850\n",
    "                            \n",
    "                    else:\n",
    "                        date='192001-200512'          \n",
    "                else:\n",
    "                    if int(em)>=34 and p==1:\n",
    "                        date='200601-210012'\n",
    "                    else:\n",
    "                        date='200601-208012'\n",
    "                        \n",
    "                fileEM=Dataset(pathCESM+var+'/b.e11.'+run+'.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\n",
    "                if em=='001':\n",
    "                    varNeeded.append(fileEM[var][840:])\n",
    "                elif f=='deltaFsw':\n",
    "                    cutVar=fileEM[var][indA+push1920:indB+push1920,:,-104:]# cut like this because it is faster\n",
    "                    varNeeded.append(cutVar[:,:,maskCBice==1])\n",
    "                else:\n",
    "                    varNeeded.append(fileEM[var][:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #mean 1970-1979 and CB\n",
    "            if f=='Fevap':# need to multiply by latent heat\n",
    "                #avg over years and position\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]*latent_heat_vapor\n",
    "                                                    for m in range(12)],axis=(1,2))\n",
    "            elif f=='Fhor':#transform from cm C s-1 to W m-2\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]*T2E/100\n",
    "                                                +varNeeded[1][indA+m:indB+m:12][:,maskCBocn==1]*T2E/100\n",
    "                                                for m in range(12)],axis=(1,2))\n",
    "            elif f=='Flw':\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]\n",
    "                                                +varNeeded[1][indA+m:indB+m:12][:,maskCBocn==1]\n",
    "                                                for m in range(12)],axis=(1,2))\n",
    "            elif f=='Fsw':\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]\n",
    "                                                -varNeeded[1][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                for m in range(12)],axis=(1,2))\n",
    "            elif f=='Flw,ai':\n",
    "                dataVar_CB=np.nanmean([(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                *varNeeded[1][indA+m:indB+m:12][:,maskCBice==1]/100)\n",
    "                                                +varNeeded[2][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                for m in range(12)],axis=(1,2))\n",
    "            elif f=='dhdt_b,l':# if lower case=> on ice grid\n",
    "                dataVar_CB=np.nanmean([-varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                -varNeeded[1][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                +varNeeded[2][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                for m in range(12)],axis=(1,2))*nbDaysInMonth\n",
    "            elif f[:4]=='dhdt':\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                for m in range(12)],axis=(1,2))*nbDaysInMonth\n",
    "            elif f=='dEdt':\n",
    "                E_sumDepth=np.nansum(np.nanmean(varNeeded[0][indA-1:indB+1][:,:,maskCBocn==1],axis=(2))*dz*T2E,axis=1)\n",
    "                wAvgTemp=[((E_sumDepth[i]*DeltaTime[i]) + (E_sumDepth[i+1]*DeltaTime[i+1]))/(DeltaTime[i]+DeltaTime[i+1]) for i in range(121)]\n",
    "                dEdt_sumDepth=[(wAvgTemp[i]-wAvgTemp[i-1])/DeltaTime[i] for i in range(1,121)]\n",
    "                dataVar_CB=np.nanmean([dEdt_sumDepth[m::12] for m in range(12)],axis=1)\n",
    "\n",
    "            elif f=='Fcb':\n",
    "                dhdtb=(varNeeded[0][indA:indB][:,maskCBice==1]-varNeeded[1][indA:indB][:,maskCBice==1])/100/86400 # m/s\n",
    "                meltl=varNeeded[2][indA:indB][:,maskCBice==1]/100/86400 # m/s\n",
    "                Fmeltb=varNeeded[3][indA:indB][:,maskCBocn==1]-(-latent_heat_fusion*rho_ice*meltl)\n",
    "                condbot_est=(-dhdtb*latent_heat_fusion*rho_ice)+Fmeltb\n",
    "                dataVar_CB=np.nanmean([condbot_est[m::12]for m in range(12)],axis=(1,2))\n",
    "\n",
    "            elif f=='Fsw,pen':\n",
    "                pen=(varNeeded[0]+varNeeded[1]+varNeeded[2]+(varNeeded[3]*varNeeded[4]/100)+varNeeded[5]-varNeeded[6])\n",
    "                dataVar_CB=np.nanmean([pen[indA+m:indB+m:12][:,maskCBice==1]for m in range(12)],axis=(1,2))\n",
    "\n",
    "            elif f=='deltaFsw':\n",
    "                #(Fsw(z=0) - Fsw(z=10) )\n",
    "                dataVar_CB=np.nanmean([(varNeeded[0][m::12,0]-varNeeded[0][m::12,1]) for m in range(12)],axis=(1,2))\n",
    "    \n",
    "            elif var[0].islower():# if lower case=> on ice grid\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                                for m in range(12)],axis=(1,2))\n",
    "                \n",
    "            else:\n",
    "                dataVar_CB=np.nanmean([varNeeded[0][indA+m:indB+m:12][:,maskCBocn==1]\n",
    "                                                for m in range(12)],axis=(1,2))\n",
    "            budget_40[p][f].append(dataVar_CB)\n",
    "\n",
    "    for f in budget_40[p]:\n",
    "        budget_40[p][f]=np.array(budget_40[p][f])\n",
    "    budget_40[p]['residual']=budget_40[p]['dEdt']-(budget_40[p]['Fsw']+budget_40[p]['Flw']+\n",
    "                                                              budget_40[p]['Fsens']+budget_40[p]['Fevap']+\n",
    "                                                              budget_40[p]['Fio']+budget_40[p]['Fhor']+\n",
    "                                                              budget_40[p]['Fsw,io']+budget_40[p]['Ffrazil'])\n",
    "    \n",
    "    budget_40[p]['R']=(budget_40[p]['Fevap']+budget_40[p]['Fsens']+budget_40[p]['Ffrazil']+budget_40[p]['Flw']+\n",
    "                        budget_40[p]['deltaFsw'])\n",
    "    \n",
    "\n",
    "    # mean, std, min,max over the 40 ems\n",
    "    meanB={}\n",
    "    stdB={}\n",
    "    maxB={}\n",
    "    minB={}\n",
    "    for f in budget_40[p]:\n",
    "        meanB[f]=np.nanmean(budget_40[p][f],axis=0)\n",
    "        stdB[f]=np.nanstd(budget_40[p][f],axis=0)\n",
    "        maxB[f]=np.nanmax(budget_40[p][f],axis=0)\n",
    "        minB[f]=np.nanmin(budget_40[p][f],axis=0)\n",
    "    budgetMean.append(meanB)\n",
    "    budgetStd.append(stdB)\n",
    "    budgetMax.append(maxB)\n",
    "    budgetMin.append(minB)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved/budgetMean.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0045e341d1c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \"\"\"\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved/budgetMean.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mbudgetMean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved/budgetMean.pickle'"
     ]
    }
   ],
   "source": [
    "# save results of code above to avoid having to rerun it\n",
    "\"\"\"\n",
    "with open('saved/budgetMean.pickle', 'wb') as handle:\n",
    "    pickle.dump(budgetMean, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/budgetStd.pickle', 'wb') as handle:\n",
    "    pickle.dump(budgetStd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/budgetMax.pickle', 'wb') as handle:\n",
    "    pickle.dump(budgetMax, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/budgetMin.pickle', 'wb') as handle:\n",
    "    pickle.dump(budgetMin, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\"\"\"\n",
    "\n",
    "with open('saved/budgetMean.pickle', 'rb') as handle:\n",
    "    budgetMean = pickle.load(handle)\n",
    "\n",
    "with open('saved/budgetStd.pickle', 'rb') as handle:\n",
    "    budgetStd = pickle.load(handle)\n",
    "    \n",
    "with open('saved/budgetMax.pickle', 'rb') as handle:\n",
    "    budgetMax = pickle.load(handle)\n",
    "\n",
    "with open('saved/budgetMin.pickle', 'rb') as handle:\n",
    "    budgetMin = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years=['1970-1979','2010-2019']\n",
    "for p in range(2):\n",
    "    print('July '+years[p])\n",
    "    for f in budgetMean[p]:\n",
    "        print('%s = %0.2f ± %1.2f '%(f,budgetMean[p][f][6],budgetStd[p][f][6]))\n",
    "    print(' ')\n",
    "    \n",
    "for p in range(2):\n",
    "    print('Feb '+years[p])\n",
    "    for f in budgetMean[p]:\n",
    "        print('%s = %0.2f ± %1.2f '%(f,budgetMean[p][f][1],budgetStd[p][f][1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seasonal cycle R(z=5m) (figure 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "fig,axs=plt.subplots(2,1,figsize=(20,15))\n",
    "axins=[inset_axes(ax, 2.945,1.8, loc='upper right',bbox_to_anchor=(0.8785,0.45),bbox_transform=ax.transAxes) for ax in axs]\n",
    "for ax in axs:\n",
    "    ax.set_ylabel('Flux divergence ($W m^{-3}$)')\n",
    "    ax.grid()\n",
    "    ax.set_ylim(-5,5)\n",
    "for axi in axins:\n",
    "    axi.set_ylim(-0.3,0.3)\n",
    "    axi.set_xlim(8,10)\n",
    "    axi.set_xticks([8,9,10])\n",
    "    axi.grid()\n",
    "    axi.set_xticklabels(['Jan','Feb','Mar'])\n",
    "\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        axi.spines[axis].set_linewidth(4)\n",
    "        axi.spines[axis].set_color('black')\n",
    "    for tick in axi.xaxis.get_major_ticks():\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    for tick in axi.yaxis.get_major_ticks():\n",
    "        tick.label1.set_fontweight('bold')\n",
    "    \n",
    "\n",
    "\n",
    "fR=['R','deltaFsw','Fevap','Fsens','Ffrazil','Flw','Fio']\n",
    "labR=['$R (z=5m)$',r'$\\frac{F_{sw}(z=0m)-F_{sw}(z=10m)}{\\Delta z}$',r'$\\frac{ F_{evap}}{\\Delta z}$',r'$\\frac{ F_{sens}}{\\Delta z}$ ',r'$ \\frac{ F_{frazil}}{\\Delta z}$  '\n",
    "      ,r'$\\frac{ F_{lw}}{\\Delta z}$ ',r'$\\frac{ F_{io}}{\\Delta z}$ ']\n",
    "colorR=['red','tab:blue','tab:purple','black','tab:pink','tab:orange','tab:green']\n",
    "linestyleR=[':','-','-','-','-','-','-.']\n",
    "linewidthR=[6,2,2,2,2,2,2]\n",
    "for p in range(2):\n",
    "    for f,label,c,ls,lw in zip(fR,labR,colorR,linestyleR,linewidthR):\n",
    "        axs[p].plot(months[4:]+months[:4],(list(budgetMean[p][f][4:])+list(budgetMean[p][f][:4]))/dz[0]\n",
    "        , linewidth=lw,color=c,label=label,linestyle=ls)\n",
    "        axins[p].plot([8,9,10],(list(budgetMean[p][f][:3]))/dz[0], linewidth=lw,alpha=1,color=c,linestyle=ls)\n",
    "\n",
    "        axs[p].fill_between(months[4:]+months[:4],(list(budgetMin[p][f][4:])+list(budgetMin[p][f][:4]))/dz[0],\n",
    "                            (list(budgetMax[p][f][4:])+list(budgetMax[p][f][:4]))/dz[0],alpha=alpha,color=c)\n",
    "        axins[p].fill_between([8,9,10],(list(budgetMin[p][f][:3]))/dz[0],(list(budgetMax[p][f][:3]))/dz[0]\n",
    "                             ,alpha=alpha,color=c)\n",
    "        \n",
    "axs[0].legend(ncol=7,loc='center',bbox_to_anchor=(0.5,-0.3),fontsize=23)\n",
    "fig.text(0.45, 0.45, '2010-2019', va='center',fontsize=35)\n",
    "fig.text(0.45, 1.02, '1970-1979', va='center',fontsize=35)\n",
    "fig.tight_layout(h_pad=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sea ice mass balance integrated over the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate different types of melt and growth over a year\n",
    "#1970s\n",
    "varByFlux['total surf melt']=['meltt']\n",
    "varByFlux['total basal melt']=['meltb','meltl']\n",
    "varByFlux['total basal growth']=['congel']\n",
    "varByFlux['summer dynamic']=['dvidtd']\n",
    "varByFlux['winter dynamic']=['dvidtd']\n",
    "winterIdx=[8,9,10,11,1,2,3,4]\n",
    "indA,indB=ind1970, ind1980\n",
    "ice_19701979_40={'total surf melt':[],'total basal melt':[],'total basal growth':[],'summer dynamic':[]\n",
    "                 ,'winter dynamic':[]}\n",
    "for em in EM:\n",
    "    print(em)\n",
    "    for f in ice_19701979_40:\n",
    "        varNeeded=[]\n",
    "        for var in varByFlux[f]:\n",
    "            #specifics of filename\n",
    "            date='192001-200512'\n",
    "            model='cice'\n",
    "            varHemi=var+'_nh'#add hemisphere for name of file\n",
    "            if em=='001':\n",
    "                date='185001-200512'\n",
    "            fileEM=Dataset(pathCESM+var+'/b.e11.B20TRC5CNBDRD.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\n",
    "            if em=='001':\n",
    "                varNeeded.append(fileEM[var][840:])\n",
    "            else:\n",
    "                varNeeded.append(fileEM[var][:])\n",
    "            \n",
    "        \n",
    "        if f== 'total basal melt':\n",
    "            dataVar_19701979_CB=np.nanmean(np.nansum([(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                            +varNeeded[1][indA+m:indB+m:12][:,maskCBice==1])*nbDaysInMonth[m]\n",
    "                                            for m in range(12)],axis=0),axis=(0,1))\n",
    "        elif f=='summer dynamic':\n",
    "            dataVar_19701979_CB=np.nanmean(np.nansum([(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1])*nbDaysInMonth[m]\n",
    "                                            for m in range(12)][5:8],axis=0),axis=(0,1))\n",
    "        elif f=='winter dynamic':\n",
    "            dataVar_19701979_CB=np.nanmean(np.nansum([[(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1])*nbDaysInMonth[m]\n",
    "                                            for m in range(12)][i] for i in winterIdx],axis=0),axis=(0,1))\n",
    "\n",
    "        else:# if lower case=> on ice grid\n",
    "            dataVar_19701979_CB=np.nanmean(np.nansum([varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]*nbDaysInMonth[m]\n",
    "                                            for m in range(12)],axis=0),axis=(0,1))\n",
    "\n",
    "        ice_19701979_40[f].append(dataVar_19701979_CB)\n",
    "\n",
    "for f in ice_19701979_40:\n",
    "    ice_19701979_40[f]=np.array(ice_19701979_40[f])\n",
    "ice_19701979={}\n",
    "iceSTD_19701979={}\n",
    "for f in ice_19701979_40:\n",
    "    ice_19701979[f]=np.nanmean(ice_19701979_40[f],axis=0)\n",
    "    iceSTD_19701979[f]=np.nanstd(ice_19701979_40[f],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as cell above but for 2010s\n",
    "indA,indB=ind2010, ind2020\n",
    "ice_20102019_40={'total surf melt':[],'total basal melt':[],'total basal growth':[],'summer dynamic':[]\n",
    "                 ,'winter dynamic':[]}\n",
    "for em in EM:\n",
    "    print(em)\n",
    "    for f in ice_20102019_40:\n",
    "        varNeeded=[]\n",
    "        for var in varByFlux[f]:\n",
    "            #specifics of filename\n",
    "            date='200601-208012'\n",
    "            model='cice'\n",
    "            varHemi=var+'_nh'#add hemisphere for name of file\n",
    "            if int(em)>=34:\n",
    "                date='200601-210012'\n",
    "            fileEM=Dataset(pathCESM+var+'/b.e11.BRCP85C5CNBDRD.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\n",
    "            if int(em)>=34:\n",
    "                varNeeded.append(fileEM[var][:-240])\n",
    "            else:\n",
    "                varNeeded.append(fileEM[var][:])\n",
    "            \n",
    "        \n",
    "        if f== 'total basal melt':\n",
    "            dataVar_20102019_CB=np.nanmean(np.nansum([(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]\n",
    "                                            +varNeeded[1][indA+m:indB+m:12][:,maskCBice==1])*nbDaysInMonth[m]\n",
    "                                            for m in range(12)],axis=0),axis=(0,1))\n",
    "        elif f=='summer dynamic':\n",
    "            dataVar_20102019_CB=np.nanmean(np.nansum([(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1])*nbDaysInMonth[m]\n",
    "                                            for m in range(12)][5:8],axis=0),axis=(0,1))\n",
    "        elif f=='winter dynamic':\n",
    "            dataVar_20102019_CB=np.nanmean(np.nansum([[(varNeeded[0][indA+m:indB+m:12][:,maskCBice==1])*nbDaysInMonth[m]\n",
    "                                            for m in range(12)][i] for i in winterIdx],axis=0),axis=(0,1))\n",
    "\n",
    "        else:# if lower case=> on ice grid\n",
    "            dataVar_20102019_CB=np.nanmean(np.nansum([varNeeded[0][indA+m:indB+m:12][:,maskCBice==1]*nbDaysInMonth[m]\n",
    "                                            for m in range(12)],axis=0),axis=(0,1))\n",
    "\n",
    "        ice_20102019_40[f].append(dataVar_20102019_CB)\n",
    "\n",
    "for f in ice_20102019_40:\n",
    "    ice_20102019_40[f]=np.array(ice_20102019_40[f])\n",
    "ice_20102019={}\n",
    "iceSTD_20102019={}\n",
    "for f in ice_20102019_40:\n",
    "    ice_20102019[f]=np.nanmean(ice_20102019_40[f],axis=0)\n",
    "    iceSTD_20102019[f]=np.nanstd(ice_20102019_40[f],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('1970-1979')\n",
    "for f in ice_19701979:\n",
    "    print('%s = %0.2f ± %1.2f '%(f,ice_19701979[f],iceSTD_19701979[f]))\n",
    "print('20102019')\n",
    "for f in ice_20102019:\n",
    "    print('%s = %0.2f ± %1.2f '%(f,ice_20102019[f],iceSTD_20102019[f]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# growth of thick ice only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1970s growth of thick ice\n",
    "alldeltah=[]\n",
    "for em in EM[1:]:\n",
    "    deltahs=[]\n",
    "    for c in range(4,6):\n",
    "        cs=str(c)\n",
    "        fvicen00c=Dataset(pathCESM+'vicen00'+cs+'/b.e11.B20TRC5CNBDRD.f09_g16.'+em+'.cice.h.vicen00'+cs+'_nh.192001-200512.nc')\n",
    "        vicen00c=np.nanmean([fvicen00c['vicen00'+cs][ind1970:ind1980][m::12,maskCBice==1]for m in range(12)],axis=(1,2))\n",
    "        deltah=np.max(vicen00c)-np.min(vicen00c)\n",
    "        deltahs.append(deltah)\n",
    "    alldeltah.append(deltahs)\n",
    "alldeltah=np.array(alldeltah) \n",
    "print(alldeltah.shape)\n",
    "print('mean: ', np.mean(alldeltah,axis=0))\n",
    "print('std:',  np.std(alldeltah,axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.35070637, 0.50397503]), np.sqrt(0.09419167**2+ 0.06848466**2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2010s growth of thick ice\n",
    "alldeltah=[]\n",
    "for em in EM:\n",
    "    deltahs=[]\n",
    "    for c in range(4,6):\n",
    "        cs=str(c)\n",
    "        enddate='208012'\n",
    "        if int(em)>33:\n",
    "            enddate='210012'\n",
    "        fvicen00c=Dataset(pathCESM+'vicen00'+cs+'/b.e11.BRCP85C5CNBDRD.f09_g16.'+em+'.cice.h.vicen00'+cs+'_nh.200601-'+enddate+'.nc')\n",
    "        vicen00c=np.nanmean([fvicen00c['vicen00'+cs][ind2010:ind2020][m::12,maskCBice==1]for m in range(12)],axis=(1,2))\n",
    "        deltah=np.max(vicen00c)-np.min(vicen00c)\n",
    "        deltahs.append(deltah)\n",
    "    alldeltah.append(deltahs)\n",
    "alldeltah=np.array(alldeltah) \n",
    "print(alldeltah.shape)\n",
    "print('mean: ', np.mean(alldeltah,axis=0))\n",
    "print('std:',  np.std(alldeltah,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([0.56981725, 0.38866577]), np.sqrt( 0.12985104**2+ 0.05054464**2)/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a",
   "language": "python",
   "name": "a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
