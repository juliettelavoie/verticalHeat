{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import netCDF4\n",
    "import pickle\n",
    "import cftime\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "SMALL_SIZE = 16\n",
    "MEDIUM_SIZE = 20\n",
    "BIGGER_SIZE = 24\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ajloaded!\n",
      "itploaded!\n"
     ]
    }
   ],
   "source": [
    "#constants\n",
    "path='/storage/jlavoie/Research/Data/Budget/'\n",
    "fTEMP=Dataset(path+'b.e11.BRCP85C5CNBDRD.f09_g16.002.pop.h.TEMP.200601-208012.nc')\n",
    "fTEMP1=Dataset(path+'b.e11.B20TRC5CNBDRD.f09_g16.002.pop.h.TEMP.192001-200512.nc')\n",
    "faice=Dataset(path+'b.e11.BRCP85C5CNBDRD.f09_g16.002.cice.h.aice_nh.200601-208012.nc')\n",
    "\n",
    "\n",
    "months=['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
    "nbDaysInMonth=[31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "\n",
    "rho_sw=fTEMP['rho_sw'][:]*1000#kg m-3\n",
    "cp_sw=fTEMP['cp_sw'][:]*0.0001#J kg-1 K-1\n",
    "T2E=rho_sw*cp_sw#J degC-1 m-3\n",
    "latent_heat_vapor=fTEMP['latent_heat_vapor'][:]\n",
    "latent_heat_fusion=fTEMP1['latent_heat_fusion'][:]*1e-7*1000# erg/g -> J/kg\n",
    "rho_ice=917#kg/m3\n",
    "\n",
    "dz=fTEMP['dz'][:]*0.01# m\n",
    "dzw=fTEMP['dzw'][:]*0.01# m\n",
    "Tf=-1.8\n",
    "tlong=fTEMP['TLONG'][:]\n",
    "tlat=fTEMP['TLAT'][:]\n",
    "tlon=faice['TLON'][:]\n",
    "tla=faice['TLAT'][:]\n",
    "z_t=fTEMP['z_t'][:]*0.01#m\n",
    "z_w=fTEMP['z_w'][:]*0.01#m\n",
    "z_w_top=fTEMP['z_w_top'][:]*0.01#m\n",
    "z_w_bot=fTEMP['z_w_bot'][:]*0.01#m\n",
    "\n",
    "\n",
    "timeDay1=fTEMP1['time']\n",
    "Jan1920=cftime.DatetimeNoLeap(1920, 1, 1, 0, 0, 0, 0, 0, 0)\n",
    "time1 = netCDF4.num2date(timeDay1[:],timeDay1.units,calendar=timeDay1.calendar)\n",
    "time1=[Jan1920]+list(time1[:-1])\n",
    "time_boundDay1=fTEMP1['time_bound']\n",
    "time_bound1 = netCDF4.num2date(time_boundDay1[:],timeDay1.units,calendar=timeDay1.calendar)\n",
    "ind1970, ind1980= 600,720\n",
    "\n",
    "timeDay=fTEMP['time']\n",
    "time = netCDF4.num2date(timeDay[:],timeDay.units,calendar=timeDay.calendar)\n",
    "#fix month error in cesm\n",
    "Jan2006=cftime.DatetimeNoLeap(2006, 1, 1, 0, 0, 0, 0, 0, 0)\n",
    "time=[Jan2006]+list(time[:-1])\n",
    "time_boundDay=fTEMP['time_bound']\n",
    "time_bound = netCDF4.num2date(time_boundDay[:],timeDay.units,calendar=timeDay.calendar)\n",
    "ind2010=12*4\n",
    "ind2020=12*14\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create mask CB\n",
    "maskCBocn=np.zeros((384,320))\n",
    "for i in range(384):\n",
    "    for j in range(320):\n",
    "        if  205<=tlong[i,j]<=230 and 72<=tlat[i,j]<=80:\n",
    "            maskCBocn[i,j]=1\n",
    "            \n",
    "maskCBice=np.zeros((104,320))\n",
    "for i in range(104):\n",
    "    for j in range(320):\n",
    "        if  205<=tlon[i,j]<=230 and 72<=tla[i,j]<=80:\n",
    "            maskCBice[i,j]=1\n",
    "\n",
    "\n",
    "pathSaved='/storage/jlavoie/Research/Data/saved/'\n",
    "with open(pathSaved+\"ajProfiles.txt\", \"rb\") as fp:  \n",
    "    ajProfiles=pickle.load(fp)\n",
    "print('ajloaded!')\n",
    "with open(pathSaved+\"itpProfiles.txt\", \"rb\") as fp:  \n",
    "    itpProfiles=pickle.load(fp)\n",
    "print('itploaded!')\n",
    "z_O=ajProfiles[0]['D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathCESM='/storage/jlavoie/Research/Data/CESM-LE/'\n",
    "\n",
    "#list of string with numberof EM\n",
    "EM=['00'+str(i) if i<10 else  '0'+str(i) if i<100 else ' '   for i in range(1,36)] +[str(i) for i in range(101,106)]\n",
    "#cesm variable needed to calculate the flux of element of the budget\n",
    "varByPro={'D':['DIA_IMPVF_TEMP','KPP_SRC_TEMP','HDIFB_TEMP','MELTH_F'],'A':['WTT'],'R':['QSW_3D','SHF','SHF_QSW','QFLUX','MELTH_F'],'dEdt':['TEMP']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#dictionnary where we store (40em,12 months) for each flux, before calculating mean and std\\ntransport_40=[{'D':[],'A':[],'R':[],'dEdt':[],'D_dia':[],'D_nl':[],'D_h':[],'Fio':[]},{'D':[],'A':[],'R':[],'dEdt':[],'D_dia':[],'D_nl':[],'D_h':[],'Fio':[]}]\\n\\ntransportMean=[]\\ntransportStd=[]\\ntransportMax=[]\\ntransportMin=[]\\n\\nblockNans=np.zeros((120, 249, 60))\\nblockNans[blockNans==0]=np.nan\\nt=3\\ntimeBD=time_boundDay[(12*t)+11:(12*t)+25]# get time for right window\\nDeltaTime=[(x[1]-x[0])*86400 for x in timeBD]# nb of days in the months and put in sec\\n\\nfor p in range(2):# iterate between 2 periods\\n    if p==0:\\n        indA,indB=ind1970,ind1980\\n        run='B20TRC5CNBDRD'\\n\\n        \\n    else:\\n        indA,indB=ind2010,ind2020\\n        run='BRCP85C5CNBDRD'\\n        \\n    for em in EM[1::]:\\n        print(em)\\n        for f in ['A','dEdt','R','D']:\\n            varNeeded=[]\\n            for var in varByPro[f]:\\n                #specifics of filename\\n                model='pop'\\n                varHemi=var\\n                if var[0].islower():\\n                    model='cice'\\n                    varHemi=var+'_nh'#add hemisphere for name of file\\n                push1920=0\\n                if p==0:\\n                    if em=='001':\\n                        date='185001-200512'\\n                        push1920=840#push index to start at 1920 not 1850\\n                    else:\\n                        date='192001-200512'          \\n                else:\\n                    if int(em)>=34 and p==1:\\n                        date='200601-210012'\\n                    else:\\n                        date='200601-208012'\\n                fileEM=Dataset(pathCESM+var+'/b.e11.'+run+'.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\\n                if var[0].islower():# ice var\\n                    cutVar=fileEM[var][indA+push1920:indB+push1920]# cut like this because it is faster\\n                    varNeeded.append(cutVar[:,maskCBice==1])\\n                elif var in ['MELTH_F','SHF','SHF_QSW','QFLUX']:# 2d not 3d\\n                    cutVar=fileEM[var][indA+push1920:indB+push1920,-104:]# cut like this because it is faster\\n                    varNeeded.append(cutVar[:,maskCBice==1])\\n                elif var =='TEMP':\\n                    cutVar=fileEM[var][indA+push1920-1:indB+push1920+1,:,-104:]# cut like this because it is faster\\n                    varNeeded.append(cutVar[:,:,maskCBice==1])\\n                else:# ocean var 3d\\n                    cutVar=fileEM[var][indA+push1920:indB+push1920,:,-104:]# cut like this because it is faster\\n                    varNeeded.append(cutVar[:,:,maskCBice==1])\\n\\n        \\n            \\n            if f=='dEdt':\\n                data_CB_all=np.zeros((10,12,249,60))\\n                for t in range(10):\\n                    # T to E\\n                    TEMP_CB_all=np.swapaxes(varNeeded[0][(12*t):(12*t)+14],1,2)\\n                    E_1=TEMP_CB_all*T2E\\n                    E_1[E_1>1e30]=np.nan\\n\\n                    #dE/dt\\n                    wAvgTemp=[((E_1[i]*DeltaTime[i]) + (E_1[i+1]*DeltaTime[i+1]))/(DeltaTime[i]+DeltaTime[i+1]) for i in range(13)]\\n                    dEdt=np.array([(wAvgTemp[i]-wAvgTemp[i-1])/DeltaTime[i] for i in range(1,13)])\\n                    data_CB_all[t,:,:,:]=dEdt\\n                data_CB_all=np.swapaxes(data_CB_all,0,1)\\n            elif f=='A':\\n                # vertical advection term with WTT \\n                WTT_1=np.swapaxes(varNeeded[0],1,2)\\n                WTT_1[abs(WTT_1)>1e30]=np.nan\\n                # add line of 0 at the bottom to keep dim (12,249,60)\\n                Adv_1=blockNans.copy()\\n                Adv_1[:,:,:-1]=-np.diff(WTT_1,axis=2)# negative because direction of diif is down but W+ is up\\n                data_CB_all=np.array([(-Adv_1*T2E)[m::12] for m in range(12)])# minus by defintion\\n            elif f=='R':\\n                #external fluxes\\n                #penetrating sw\\n                QSW_3D_1=np.swapaxes(varNeeded[0],1,2)#watt/m^2\\n                QSW_3D_1[abs(QSW_3D_1)>1e30]=np.nan\\n                QSW_3D_1_z=blockNans.copy()  # add line of nans at the bottom to keep dim (12,249,60) instead of 59\\n                QSW_3D_1_z[:,:,:-1]=-np.diff(QSW_3D_1)/dz[:-1]#  also - because going down\\n                #other fluxes\\n                Fother_1=np.zeros((120, 249, 60))\\n                Fother_1[:,:,0]=(varNeeded[1]\\n                                -varNeeded[2]\\n                                 +varNeeded[3]\\n                                -varNeeded[4])/dz[0]\\n                Fother_1[abs(Fother_1)>1e30]=np.nan\\n                data_CB_all=np.array([(QSW_3D_1_z + Fother_1)[m::12] for m in range(12)])\\n            elif f=='D':\\n                #vertical diffusion from TEMP Flux Across Bottom Face from Diabatic Implicit Vertical Mixing\\n                DIA_IMPVF_TEMP_1=np.zeros((120, 249, 61))# add line of 0 at the top to be in z_w instead of z_w_bot\\n                DIA_IMPVF_TEMP_1[:,:,1:]=np.swapaxes(varNeeded[0]/100,1,2) #degC m s-1 \\n                DIA_IMPVF_TEMP_1[abs(DIA_IMPVF_TEMP_1)>1e30]=np.nan\\n                DIA_IMPVF_TEMP_z_1=np.array([(-np.diff(DIA_IMPVF_TEMP_1)/dz*T2E)[m::12] for m in range(12)])# neg. diff towards bottom #degC s-1\\n\\n\\n                #vm from non local KPP\\n                nonLocalTerm=np.array([(np.swapaxes(varNeeded[1],1,2)*T2E)[m::12] for m in range(12)])\\n\\n                #flux through bottom face from MG param (horizontal diff)\\n                HDIFB_TEMP_1=np.zeros((120, 249, 61))# add line of 0 at the top to be in z_w instead of z_w_bot\\n                HDIFB_TEMP_1[:,:,1:]=np.swapaxes(varNeeded[2],1,2)\\n                HDIFB_TEMP_1[abs(HDIFB_TEMP_1)>1e30]=np.nan\\n                HDIFB_TEMP_z_1=np.array([(-np.diff(HDIFB_TEMP_1)*T2E)[m::12] for m in range(12)])# neg. diff towards bottom #degC s-1\\n\\n\\n                #turbulent ice-ocean flux\\n                Fio=np.zeros((12,10, 249, 60))\\n                Fio[:,:,:,0]=[(varNeeded[3]/dz[0])[m::12] for m in range(12)]\\n\\n                #sum\\n                data_CB_all=DIA_IMPVF_TEMP_z_1+nonLocalTerm+HDIFB_TEMP_z_1+Fio\\n                transport_40[p]['D_dia'].append(np.nanmean(DIA_IMPVF_TEMP_z_1,axis=(1,2)))\\n                transport_40[p]['D_nl'].append(np.nanmean(nonLocalTerm,axis=(1,2)))\\n                transport_40[p]['D_h'].append(np.nanmean(HDIFB_TEMP_z_1,axis=(1,2)))\\n                transport_40[p]['Fio'].append(np.nanmean(Fio,axis=(1,2)))\\n\\n            \\n            transport_40[p][f].append(np.nanmean(data_CB_all,axis=(1,2)))\\n        \\n\\n    \\n    for f in transport_40[p]:\\n        transport_40[p][f]=np.array(transport_40[p][f])\\n        \\n    transport_40[p]['residual']=(transport_40[p]['dEdt']\\n                    -(transport_40[p]['R']+transport_40[p]['D']+transport_40[p]['A']))\\n\\n    meanP={}\\n    stdP={}\\n    maxP={}\\n    minP={}\\n    for f in transport_40[p]:\\n        meanP[f]=np.nanmean(transport_40[p][f],axis=0)\\n        stdP[f]=np.nanstd(transport_40[p][f],axis=0)\\n        maxP[f]=np.nanmax(transport_40[p][f],axis=0)\\n        minP[f]=np.nanmin(transport_40[p][f],axis=0)\\n    transportMean.append(meanP)\\n    transportStd.append(stdP)\\n    transportMax.append(maxP)\\n    transportMin.append(minP)\\n\\n    \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#dictionnary where we store (40em,12 months) for each flux, before calculating mean and std\n",
    "transport_40=[{'D':[],'A':[],'R':[],'dEdt':[],'D_dia':[],'D_nl':[],'D_h':[],'Fio':[]},{'D':[],'A':[],'R':[],'dEdt':[],'D_dia':[],'D_nl':[],'D_h':[],'Fio':[]}]\n",
    "\n",
    "transportMean=[]\n",
    "transportStd=[]\n",
    "transportMax=[]\n",
    "transportMin=[]\n",
    "\n",
    "blockNans=np.zeros((120, 249, 60))\n",
    "blockNans[blockNans==0]=np.nan\n",
    "t=3\n",
    "timeBD=time_boundDay[(12*t)+11:(12*t)+25]# get time for right window\n",
    "DeltaTime=[(x[1]-x[0])*86400 for x in timeBD]# nb of days in the months and put in sec\n",
    "\n",
    "for p in range(2):# iterate between 2 periods\n",
    "    if p==0:\n",
    "        indA,indB=ind1970,ind1980\n",
    "        run='B20TRC5CNBDRD'\n",
    "\n",
    "        \n",
    "    else:\n",
    "        indA,indB=ind2010,ind2020\n",
    "        run='BRCP85C5CNBDRD'\n",
    "        \n",
    "    for em in EM[1::]:\n",
    "        print(em)\n",
    "        for f in ['A','dEdt','R','D']:\n",
    "            varNeeded=[]\n",
    "            for var in varByPro[f]:\n",
    "                #specifics of filename\n",
    "                model='pop'\n",
    "                varHemi=var\n",
    "                if var[0].islower():\n",
    "                    model='cice'\n",
    "                    varHemi=var+'_nh'#add hemisphere for name of file\n",
    "                push1920=0\n",
    "                if p==0:\n",
    "                    if em=='001':\n",
    "                        date='185001-200512'\n",
    "                        push1920=840#push index to start at 1920 not 1850\n",
    "                    else:\n",
    "                        date='192001-200512'          \n",
    "                else:\n",
    "                    if int(em)>=34 and p==1:\n",
    "                        date='200601-210012'\n",
    "                    else:\n",
    "                        date='200601-208012'\n",
    "                fileEM=Dataset(pathCESM+var+'/b.e11.'+run+'.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\n",
    "                if var[0].islower():# ice var\n",
    "                    cutVar=fileEM[var][indA+push1920:indB+push1920]# cut like this because it is faster\n",
    "                    varNeeded.append(cutVar[:,maskCBice==1])\n",
    "                elif var in ['MELTH_F','SHF','SHF_QSW','QFLUX']:# 2d not 3d\n",
    "                    cutVar=fileEM[var][indA+push1920:indB+push1920,-104:]# cut like this because it is faster\n",
    "                    varNeeded.append(cutVar[:,maskCBice==1])\n",
    "                elif var =='TEMP':\n",
    "                    cutVar=fileEM[var][indA+push1920-1:indB+push1920+1,:,-104:]# cut like this because it is faster\n",
    "                    varNeeded.append(cutVar[:,:,maskCBice==1])\n",
    "                else:# ocean var 3d\n",
    "                    cutVar=fileEM[var][indA+push1920:indB+push1920,:,-104:]# cut like this because it is faster\n",
    "                    varNeeded.append(cutVar[:,:,maskCBice==1])\n",
    "\n",
    "        \n",
    "            \n",
    "            if f=='dEdt':\n",
    "                data_CB_all=np.zeros((10,12,249,60))\n",
    "                for t in range(10):\n",
    "                    # T to E\n",
    "                    TEMP_CB_all=np.swapaxes(varNeeded[0][(12*t):(12*t)+14],1,2)\n",
    "                    E_1=TEMP_CB_all*T2E\n",
    "                    E_1[E_1>1e30]=np.nan\n",
    "\n",
    "                    #dE/dt\n",
    "                    wAvgTemp=[((E_1[i]*DeltaTime[i]) + (E_1[i+1]*DeltaTime[i+1]))/(DeltaTime[i]+DeltaTime[i+1]) for i in range(13)]\n",
    "                    dEdt=np.array([(wAvgTemp[i]-wAvgTemp[i-1])/DeltaTime[i] for i in range(1,13)])\n",
    "                    data_CB_all[t,:,:,:]=dEdt\n",
    "                data_CB_all=np.swapaxes(data_CB_all,0,1)\n",
    "            elif f=='A':\n",
    "                # vertical advection term with WTT \n",
    "                WTT_1=np.swapaxes(varNeeded[0],1,2)\n",
    "                WTT_1[abs(WTT_1)>1e30]=np.nan\n",
    "                # add line of 0 at the bottom to keep dim (12,249,60)\n",
    "                Adv_1=blockNans.copy()\n",
    "                Adv_1[:,:,:-1]=-np.diff(WTT_1,axis=2)# negative because direction of diif is down but W+ is up\n",
    "                data_CB_all=np.array([(-Adv_1*T2E)[m::12] for m in range(12)])# minus by defintion\n",
    "            elif f=='R':\n",
    "                #external fluxes\n",
    "                #penetrating sw\n",
    "                QSW_3D_1=np.swapaxes(varNeeded[0],1,2)#watt/m^2\n",
    "                QSW_3D_1[abs(QSW_3D_1)>1e30]=np.nan\n",
    "                QSW_3D_1_z=blockNans.copy()  # add line of nans at the bottom to keep dim (12,249,60) instead of 59\n",
    "                QSW_3D_1_z[:,:,:-1]=-np.diff(QSW_3D_1)/dz[:-1]#  also - because going down\n",
    "                #other fluxes\n",
    "                Fother_1=np.zeros((120, 249, 60))\n",
    "                Fother_1[:,:,0]=(varNeeded[1]\n",
    "                                -varNeeded[2]\n",
    "                                 +varNeeded[3]\n",
    "                                -varNeeded[4])/dz[0]\n",
    "                Fother_1[abs(Fother_1)>1e30]=np.nan\n",
    "                data_CB_all=np.array([(QSW_3D_1_z + Fother_1)[m::12] for m in range(12)])\n",
    "            elif f=='D':\n",
    "                #vertical diffusion from TEMP Flux Across Bottom Face from Diabatic Implicit Vertical Mixing\n",
    "                DIA_IMPVF_TEMP_1=np.zeros((120, 249, 61))# add line of 0 at the top to be in z_w instead of z_w_bot\n",
    "                DIA_IMPVF_TEMP_1[:,:,1:]=np.swapaxes(varNeeded[0]/100,1,2) #degC m s-1 \n",
    "                DIA_IMPVF_TEMP_1[abs(DIA_IMPVF_TEMP_1)>1e30]=np.nan\n",
    "                DIA_IMPVF_TEMP_z_1=np.array([(-np.diff(DIA_IMPVF_TEMP_1)/dz*T2E)[m::12] for m in range(12)])# neg. diff towards bottom #degC s-1\n",
    "\n",
    "\n",
    "                #vm from non local KPP\n",
    "                nonLocalTerm=np.array([(np.swapaxes(varNeeded[1],1,2)*T2E)[m::12] for m in range(12)])\n",
    "\n",
    "                #flux through bottom face from MG param (horizontal diff)\n",
    "                HDIFB_TEMP_1=np.zeros((120, 249, 61))# add line of 0 at the top to be in z_w instead of z_w_bot\n",
    "                HDIFB_TEMP_1[:,:,1:]=np.swapaxes(varNeeded[2],1,2)\n",
    "                HDIFB_TEMP_1[abs(HDIFB_TEMP_1)>1e30]=np.nan\n",
    "                HDIFB_TEMP_z_1=np.array([(-np.diff(HDIFB_TEMP_1)*T2E)[m::12] for m in range(12)])# neg. diff towards bottom #degC s-1\n",
    "\n",
    "\n",
    "                #turbulent ice-ocean flux\n",
    "                Fio=np.zeros((12,10, 249, 60))\n",
    "                Fio[:,:,:,0]=[(varNeeded[3]/dz[0])[m::12] for m in range(12)]\n",
    "\n",
    "                #sum\n",
    "                data_CB_all=DIA_IMPVF_TEMP_z_1+nonLocalTerm+HDIFB_TEMP_z_1+Fio\n",
    "                transport_40[p]['D_dia'].append(np.nanmean(DIA_IMPVF_TEMP_z_1,axis=(1,2)))\n",
    "                transport_40[p]['D_nl'].append(np.nanmean(nonLocalTerm,axis=(1,2)))\n",
    "                transport_40[p]['D_h'].append(np.nanmean(HDIFB_TEMP_z_1,axis=(1,2)))\n",
    "                transport_40[p]['Fio'].append(np.nanmean(Fio,axis=(1,2)))\n",
    "\n",
    "            \n",
    "            transport_40[p][f].append(np.nanmean(data_CB_all,axis=(1,2)))\n",
    "        \n",
    "\n",
    "    \n",
    "    for f in transport_40[p]:\n",
    "        transport_40[p][f]=np.array(transport_40[p][f])\n",
    "        \n",
    "    transport_40[p]['residual']=(transport_40[p]['dEdt']\n",
    "                    -(transport_40[p]['R']+transport_40[p]['D']+transport_40[p]['A']))\n",
    "\n",
    "    meanP={}\n",
    "    stdP={}\n",
    "    maxP={}\n",
    "    minP={}\n",
    "    for f in transport_40[p]:\n",
    "        meanP[f]=np.nanmean(transport_40[p][f],axis=0)\n",
    "        stdP[f]=np.nanstd(transport_40[p][f],axis=0)\n",
    "        maxP[f]=np.nanmax(transport_40[p][f],axis=0)\n",
    "        minP[f]=np.nanmin(transport_40[p][f],axis=0)\n",
    "    transportMean.append(meanP)\n",
    "    transportStd.append(stdP)\n",
    "    transportMax.append(maxP)\n",
    "    transportMin.append(minP)\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('saved/transportMean.pickle', 'wb') as handle:\n",
    "    pickle.dump(transportMean, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/transportStd.pickle', 'wb') as handle:\n",
    "    pickle.dump(transportStd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('saved/transportMax.pickle', 'wb') as handle:\n",
    "    pickle.dump(transportMax, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/transportMin.pickle', 'wb') as handle:\n",
    "    pickle.dump(transportMin, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('saved/transportMean.pickle', 'rb') as handle:\n",
    "    transportMean = pickle.load(handle)\n",
    "\n",
    "with open('saved/transportStd.pickle', 'rb') as handle:\n",
    "    transportStd = pickle.load(handle)\n",
    "with open('saved/transportMax.pickle', 'rb') as handle:\n",
    "    transportMax = pickle.load(handle)\n",
    "\n",
    "with open('saved/transportMin.pickle', 'rb') as handle:\n",
    "    transportMin = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved/CESMmean.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ee0b054d0a44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved/CESMmean.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mCESMmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'saved/CESMstd.pickle'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mCESMstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved/CESMmean.pickle'"
     ]
    }
   ],
   "source": [
    "with open('saved/CESMmean.pickle', 'rb') as handle:\n",
    "    CESMmean = pickle.load(handle)\n",
    "\n",
    "with open('saved/CESMstd.pickle', 'rb') as handle:\n",
    "    CESMstd = pickle.load(handle)\n",
    "with open('saved/CESMmax.pickle', 'rb') as handle:\n",
    "    CESMmax = pickle.load(handle)\n",
    "\n",
    "with open('saved/CESMmin.pickle', 'rb') as handle:\n",
    "    CESMmin = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70s,10s, diff. 5 months\n",
    "\n",
    "ylim=(120,0)\n",
    "xlim=(-1.4,1.4)#\n",
    "lw=2\n",
    "alpha=0.1\n",
    "fig, axs = plt.subplots(3, 5, figsize=(20,20),sharey=True)\n",
    "x=0\n",
    "terms=['dEdt','A','R','D','residual']\n",
    "labels=[r'$\\frac{\\partial  E}{\\partial t}$',r'$-\\frac{\\partial ( E w)}{\\partial z}$',r'$ R$',r'$D$','residual']\n",
    "colors=['green','blue','red','orange','grey']\n",
    "linestyle=['-','-','-','-',':']\n",
    "\n",
    "for monthInd in [4,6,8,11,1]:\n",
    "    for f, label,c,ls in zip(terms,labels,colors,linestyle):\n",
    "        for p in range(2):\n",
    "            y=p\n",
    "            axs[y][x].set_xlabel(r'$W m^{-3}$')\n",
    "\n",
    "            axs[y][x].plot(transportMean[p][f][monthInd],z_t,color=c,linewidth=lw,linestyle=ls,\n",
    "                           label=label if monthInd==1 and p==0 else None)\n",
    "            axs[y][x].fill_betweenx(z_t,transportMin[p][f][monthInd],transportMax[p][f][monthInd],color=c\n",
    "                                    ,linewidth=lw,linestyle=ls,alpha=alpha)\n",
    "\n",
    "            axs[y][x].errorbar(xlim[1]-0.01,CESMmean[p]['MLD'][monthInd],yerr=\n",
    "                               np.reshape([(CESMmean[p]['MLD'][monthInd]-CESMmin[p]['MLD'][monthInd]),\n",
    "                                (CESMmax[p]['MLD'][monthInd]-CESMmean[p]['MLD'][monthInd])], (2,1))\n",
    "                               ,fmt='<',color='black',markersize=20,capsize=5)\n",
    "            axs[y][x].set_xlim(xlim)\n",
    "            axs[y][x].grid(axis='both')\n",
    "            axs[y][x].set_title(months[monthInd],fontsize=20)\n",
    "\n",
    "        #difference\n",
    "        y=2\n",
    "        axs[y][x].plot(transportMean[1][f][monthInd]-transportMean[0][f][monthInd],z_t,color=c,\n",
    "                       linewidth=lw,linestyle=ls)\n",
    "        axs[y][x].fill_betweenx(z_t,transportMin[1][f][monthInd]-transportMin[0][f][monthInd],\n",
    "                       transportMax[1][f][monthInd]-transportMax[0][f][monthInd],color=c,\n",
    "                       linewidth=lw,linestyle=ls,alpha=alpha)\n",
    "        axs[y][x].set_xlabel(r'$W m^{-3}$')    \n",
    "        axs[y][x].set_xlim(xlim)\n",
    "        axs[y][x].grid(axis='both')\n",
    "        axs[y][x].set_title(months[monthInd],fontsize=20)\n",
    "\n",
    "\n",
    "    x+=1\n",
    "fig.legend(ncol=6,bbox_to_anchor=(0.5,1.08),loc='center',fontsize=25)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylim(ylim)\n",
    "fig.text(-0.01, 0.49, 'Depth (m)', va='center', rotation='vertical',fontsize=25)\n",
    "fig.text(0.45, 0.66, '2010-2019', va='center',fontsize=35)\n",
    "fig.text(0.45, 1.01, '1970-1979', va='center',fontsize=35)\n",
    "fig.text(0.38, 0.31, 'Difference (10s - 70s)', va='center',fontsize=35)\n",
    "\n",
    "\n",
    "\n",
    "fig.tight_layout(h_pad=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70s,10s, diff. 5 months\n",
    "\n",
    "ylim=(120,0)\n",
    "xlim=(-1.4,1.4)#\n",
    "alpha=0.1\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20,15),sharey=True)\n",
    "x=0\n",
    "terms=['D','D_dia', 'D_nl', 'D_h', 'Fio']\n",
    "labels=['D',r'$D_{dia}$',r'$D_{nl}$',r'$D_{iso}$',r'$\\nabla F_{io}$']\n",
    "colors=['orange','c','m','y','g']\n",
    "linestyle=['-','-','-','-','-']\n",
    "linewidths=[4,1,1,1,1]\n",
    "for monthInd in [4,6,8,11,1]:\n",
    "    axs[0][x].grid()\n",
    "    axs[1][x].grid()\n",
    "    for f, label,c,ls,lw in zip(terms,labels,colors,linestyle,linewidths):\n",
    "        for p in range(2):\n",
    "            y=p\n",
    "            axs[y][x].set_xlabel(r'$W m^{-3}$')\n",
    "\n",
    "            axs[y][x].plot(transportMean[p][f][monthInd],z_t,color=c,linewidth=lw,linestyle=ls,\n",
    "                           label=label if monthInd==1 and p==0 else None)\n",
    "            axs[y][x].fill_betweenx(z_t,transportMin[p][f][monthInd],transportMax[p][f][monthInd],color=c\n",
    "                                    ,linewidth=lw,linestyle=ls,alpha=alpha)\n",
    "\n",
    "            axs[y][x].errorbar(xlim[1]-0.01,CESMmean[p]['MLD'][monthInd],yerr=\n",
    "                               np.reshape([(CESMmean[p]['MLD'][monthInd]-CESMmin[p]['MLD'][monthInd]),\n",
    "                                (CESMmax[p]['MLD'][monthInd]-CESMmean[p]['MLD'][monthInd])], (2,1))\n",
    "                               ,fmt='<',color='black',markersize=20,capsize=5)\n",
    "            axs[y][x].set_xlim(xlim)\n",
    "            axs[y][x].set_title(months[monthInd],fontsize=20)\n",
    "\n",
    "    x+=1\n",
    "fig.legend(ncol=6,bbox_to_anchor=(0.5,1.08),loc='center',fontsize=25)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylim(ylim)\n",
    "fig.text(-0.01, 0.49, 'Depth (m)', va='center', rotation='vertical',fontsize=25)\n",
    "fig.text(0.45, 0.48, '2010-2019', va='center',fontsize=35)\n",
    "fig.text(0.45, 1.01, '1970-1979', va='center',fontsize=35)\n",
    "fig.tight_layout(h_pad=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# horizontal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#dictionnary where we store (40em,12 months) for each flux, before calculating mean and std\n",
    "horizontal_40=[{'adv':[],'diff':[]},{'adv':[],'diff':[]}]\n",
    "varByPro['adv']=['UET','VNT']\n",
    "varByPro['diff']=['HDIFE_TEMP','HDIFN_TEMP']\n",
    "\n",
    "horizontalMean=[]\n",
    "horizontalStd=[]\n",
    "horizontalMax=[]\n",
    "horizontalMin=[]\n",
    "bs,cs=np.where(maskCBice == 1)\n",
    "for p in range(2):# iterate between 2 periods\n",
    "    if p==0:\n",
    "        indA,indB=ind1970,ind1980\n",
    "        run='B20TRC5CNBDRD'\n",
    "    else:\n",
    "        indA,indB=ind2010,ind2020\n",
    "        run='BRCP85C5CNBDRD'  \n",
    "    for em in EM[1::]:\n",
    "        print(em)\n",
    "        for f in horizontal_40[p]:\n",
    "            varNeeded=[]\n",
    "            for var in varByPro[f]:\n",
    "                #specifics of filename\n",
    "                model='pop'\n",
    "                varHemi=var\n",
    "                if var[0].islower():\n",
    "                    model='cice'\n",
    "                    varHemi=var+'_nh'#add hemisphere for name of file\n",
    "                push1920=0\n",
    "                if p==0:\n",
    "                    if em=='001':\n",
    "                        date='185001-200512'\n",
    "                        push1920=840#push index to start at 1920 not 1850\n",
    "                    else:\n",
    "                        date='192001-200512'          \n",
    "                else:\n",
    "                    if int(em)>=34 and p==1:\n",
    "                        date='200601-210012'\n",
    "                    else:\n",
    "                        date='200601-208012'\n",
    "                fileEM=Dataset(pathCESM+var+'/b.e11.'+run+'.f09_g16.'+em+'.'+model+'.h.'+varHemi+'.'+date+'.nc')\n",
    "                cutVar=fileEM[var][indA+push1920:indB+push1920,:,-104:]# cut like this because it is faster\n",
    "                varNeeded.append(cutVar)# dont cut CB right now\n",
    "        \n",
    "        \n",
    "            if f=='adv':\n",
    "                sign=+1\n",
    "            elif f=='diff':\n",
    "                sign=-1\n",
    "            x_indiv=[]\n",
    "            y_indiv=[]\n",
    "            for x,y in zip(bs,cs):\n",
    "            # here we are doing flux before cell - flux after cell\n",
    "            # gradient would be after- before\n",
    "            # advection is define as - gradient \n",
    "            # we are calculating adv directly.\n",
    "                x_indiv.append(sign*(varNeeded[0][:,:,x,y-1]-varNeeded[0][:,:,x,y]))\n",
    "                y_indiv.append(sign*(varNeeded[1][:,:,x-1,y]-varNeeded[1][:,:,x,y]))\n",
    "            x_indiv=np.array(x_indiv)\n",
    "            y_indiv=np.array(y_indiv)\n",
    "            x_indiv=np.swapaxes([x_indiv[:,m::12] for m in range(12)],1,2)*T2E\n",
    "            y_indiv=np.swapaxes([y_indiv[:,m::12] for m in range(12)],1,2)*T2E\n",
    "\n",
    "            data_CB_all=x_indiv+y_indiv\n",
    "                \n",
    "\n",
    "            horizontal_40[p][f].append(np.nanmean(data_CB_all,axis=(1,2)))\n",
    "        \n",
    "\n",
    "    \n",
    "    for f in horizontal_40[p]:\n",
    "        horizontal_40[p][f]=np.array(horizontal_40[p][f])\n",
    "    \n",
    "    horizontal_40[p]['sum']=horizontal_40[p]['adv']+horizontal_40[p]['diff']\n",
    "    horizontal_40[p]['residualHor']=transport_40[p]['residual']-horizontal_40[p]['sum']\n",
    "\n",
    "    meanP={}\n",
    "    stdP={}\n",
    "    maxP={}\n",
    "    minP={}\n",
    "    for f in horizontal_40[p]:\n",
    "        meanP[f]=np.nanmean(horizontal_40[p][f],axis=0)\n",
    "        stdP[f]=np.nanstd(horizontal_40[p][f],axis=0)\n",
    "        maxP[f]=np.nanmax(horizontal_40[p][f],axis=0)\n",
    "        minP[f]=np.nanmin(horizontal_40[p][f],axis=0)\n",
    "    horizontalMean.append(meanP)\n",
    "    horizontalStd.append(stdP)\n",
    "    horizontalMax.append(maxP)\n",
    "    horizontalMin.append(minP)\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "with open('saved/horizontalMean.pickle', 'wb') as handle:\n",
    "    pickle.dump(horizontalMean, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/horizontalStd.pickle', 'wb') as handle:\n",
    "    pickle.dump(horizontalStd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('saved/horizontalMax.pickle', 'wb') as handle:\n",
    "    pickle.dump(horizontalMax, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('saved/horizontalMin.pickle', 'wb') as handle:\n",
    "    pickle.dump(horizontalMin, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open('saved/horizontalMean.pickle', 'rb') as handle:\n",
    "    horizontalMean = pickle.load(handle)\n",
    "\n",
    "with open('saved/horizontalStd.pickle', 'rb') as handle:\n",
    "    horizontalStd = pickle.load(handle)\n",
    "with open('saved/horizontalMax.pickle', 'rb') as handle:\n",
    "    horizontalMax = pickle.load(handle)\n",
    "\n",
    "with open('saved/horizontalMin.pickle', 'rb') as handle:\n",
    "    horizontalMin = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70s,10s, diff. 5 months\n",
    "\n",
    "ylim=(120,0)\n",
    "xlim=(-1.4,1.4)#\n",
    "alpha=0.1\n",
    "fig, axs = plt.subplots(2, 5, figsize=(20,15),sharey=True)\n",
    "x=0\n",
    "\n",
    "lw=2\n",
    "for monthInd in [4,6,8,11,1]:\n",
    "    axs[0][x].grid()\n",
    "    axs[1][x].grid()\n",
    "    for p in range(2):\n",
    "        y=p\n",
    "        axs[y][x].set_xlabel(r'$W m^{-3}$')\n",
    "\n",
    "        axs[y][x].plot(horizontalMean[p]['sum'][monthInd],z_t,color='fuchsia',linewidth=lw,linestyle='-',\n",
    "                       label=r'$\\frac{\\partial F_{hor}}{\\partial z}$' if monthInd==1 and p==0 else None)\n",
    "        axs[y][x].fill_betweenx(z_t,horizontalMin[p]['sum'][monthInd],horizontalMax[p]['sum'][monthInd],color='fuchsia'\n",
    "                                ,linewidth=lw,alpha=alpha)\n",
    "        \n",
    "        axs[y][x].plot(horizontalMean[p]['residualHor'][monthInd],z_t,color='grey',linewidth=lw,linestyle='-.',\n",
    "                       label=r'$residual -\\frac{\\partial F_{hor}}{\\partial z}$' if monthInd==1 and p==0 else None)\n",
    "        axs[y][x].fill_betweenx(z_t,horizontalMin[p]['residualHor'][monthInd],horizontalMax[p]['residualHor'][monthInd]\n",
    "                                ,color='grey',alpha=alpha)\n",
    "        \n",
    "        axs[y][x].plot(transportMean[p]['residual'][monthInd],z_t,color='grey',linewidth=lw,linestyle=':',\n",
    "                       label=r'residual' if monthInd==1 and p==0 else None)\n",
    "        axs[y][x].fill_betweenx(z_t,transportMin[p]['residual'][monthInd],transportMax[p]['residual'][monthInd]\n",
    "                                ,color='grey',alpha=alpha)\n",
    "\n",
    "        axs[y][x].errorbar(xlim[1]-0.01,CESMmean[p]['MLD'][monthInd],yerr=\n",
    "                           np.reshape([(CESMmean[p]['MLD'][monthInd]-CESMmin[p]['MLD'][monthInd]),\n",
    "                            (CESMmax[p]['MLD'][monthInd]-CESMmean[p]['MLD'][monthInd])], (2,1))\n",
    "                           ,fmt='<',color='black',markersize=20,capsize=5)\n",
    "        axs[y][x].set_xlim(xlim)\n",
    "        axs[y][x].set_title(months[monthInd],fontsize=20)\n",
    "\n",
    "    x+=1\n",
    "fig.legend(ncol=6,bbox_to_anchor=(0.5,1.08),loc='center',fontsize=25)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.ylim(ylim)\n",
    "fig.text(-0.01, 0.49, 'Depth (m)', va='center', rotation='vertical',fontsize=25)\n",
    "fig.text(0.45, 0.48, '2010-2019', va='center',fontsize=35)\n",
    "fig.text(0.45, 1.01, '1970-1979', va='center',fontsize=35)\n",
    "fig.tight_layout(h_pad=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a",
   "language": "python",
   "name": "a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
